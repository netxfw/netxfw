//go:build linux
// +build linux

package xdp

import (
	"fmt"
	"log"
	"net"
	"net/netip"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"time"

	"github.com/cilium/ebpf"
	"github.com/cilium/ebpf/link"
	"github.com/cilium/ebpf/rlimit"
	"github.com/livp123/netxfw/internal/config"
	"github.com/livp123/netxfw/internal/plugins/types"
	"github.com/livp123/netxfw/internal/utils/fileutil"
	"github.com/livp123/netxfw/internal/utils/iputil"
)

const (
	CONFIG_DEFAULT_DENY         = 0
	CONFIG_ALLOW_RETURN_TRAFFIC = 1
	CONFIG_ALLOW_ICMP           = 2
	CONFIG_ENABLE_CONNTRACK     = 3
	CONFIG_CONNTRACK_TIMEOUT    = 4
	CONFIG_ICMP_RATE            = 5
	CONFIG_ICMP_BURST           = 6
	CONFIG_ENABLE_AF_XDP        = 7
	CONFIG_CONFIG_VERSION       = 8
	CONFIG_STRICT_PROTO         = 9
	CONFIG_ENABLE_RATELIMIT     = 10
	CONFIG_DROP_FRAGMENTS       = 11
	CONFIG_STRICT_TCP           = 12
	CONFIG_SYN_LIMIT            = 13
	CONFIG_BOGON_FILTER         = 14
	CONFIG_AUTO_BLOCK           = 15
	CONFIG_AUTO_BLOCK_EXPIRY    = 16
)

// BlockStatic adds an IP to the static blocklist (LPM trie) and optionally persists it to a file.
// It reuses the underlying LockIP helper for BPF map operations.
// BlockStatic å°† IP æ·»åŠ åˆ°é™æ€é»‘åå•ï¼ˆLPM Trieï¼‰å¹¶å¯é€‰æ‹©å°†å…¶æŒä¹…åŒ–åˆ°æ–‡ä»¶ã€‚
// å®ƒå¤ç”¨åº•å±‚çš„ LockIP è¾…åŠ©å‡½æ•°è¿›è¡Œ BPF Map æ“ä½œã€‚
func (m *Manager) BlockStatic(ipStr string, persistFile string) error {
	ipNet, err := iputil.ParseCIDR(ipStr)
	if err != nil {
		return fmt.Errorf("invalid IP or CIDR %s: %w", ipStr, err)
	}
	cidr := ipNet.String()

	// Use LockList (Static)
	// ä½¿ç”¨ LockListï¼ˆé™æ€ï¼‰
	mapObj := m.LockList()

	// Reuse existing LockIP helper
	// å¤ç”¨ç°æœ‰çš„ LockIP è¾…åŠ©å‡½æ•°
	if err := LockIP(mapObj, cidr); err != nil {
		return fmt.Errorf("failed to add to static blacklist %s: %v", cidr, err)
	}

	// Persist to lock list file if configured
	// å¦‚æœé…ç½®äº†ï¼ŒæŒä¹…åŒ–åˆ°é”å®šåˆ—è¡¨æ–‡ä»¶
	if persistFile != "" {
		if err := fileutil.AppendToFile(persistFile, cidr); err != nil {
			log.Printf("âš ï¸ Failed to write to lock list file: %v", err)
		} else {
			log.Printf("ğŸ’¾ Persisted IP %s to %s", cidr, persistFile)
		}
	}

	log.Printf("ğŸš« Added IP %s to STATIC blacklist (permanent)", cidr)
	return nil
}

// AllowStatic adds an IP/CIDR to the whitelist.
// AllowStatic å°† IP/CIDR æ·»åŠ åˆ°ç™½åå•ã€‚
func (m *Manager) AllowStatic(ipStr string, port uint16) error {
	mapObj := m.Whitelist()

	if err := AllowIP(mapObj, ipStr, port); err != nil {
		return fmt.Errorf("failed to allow %s: %v", ipStr, err)
	}
	return nil
}

// RemoveAllowStatic removes an IP/CIDR from the whitelist.
// RemoveAllowStatic ä»ç™½åå•ä¸­ç§»é™¤ IP/CIDRã€‚
func (m *Manager) RemoveAllowStatic(ipStr string) error {
	mapObj := m.Whitelist()

	if err := UnlockIP(mapObj, ipStr); err != nil {
		return fmt.Errorf("failed to remove from whitelist %s: %v", ipStr, err)
	}
	return nil
}

// ListWhitelist returns all whitelisted IPs/CIDRs.
// ListWhitelist è¿”å›æ‰€æœ‰ç™½åå•ä¸­çš„ IP/CIDRã€‚
func (m *Manager) ListWhitelist(isIPv6 bool) ([]string, error) {
	mapObj := m.Whitelist()
	// Use 0 limit to get all
	// ä½¿ç”¨ 0 é™åˆ¶ä»¥è·å–å…¨éƒ¨
	ips, _, err := ListWhitelistedIPs(mapObj, isIPv6, 0, "")
	return ips, err
}

// BlockDynamic adds an IP to the dynamic blocklist (LRU hash) with a TTL.
// BlockDynamic å°† IP æ·»åŠ åˆ°å¸¦æœ‰ TTL çš„åŠ¨æ€é»‘åå•ï¼ˆLRU Hashï¼‰ä¸­ã€‚
func (m *Manager) BlockDynamic(ipStr string, ttl time.Duration) error {
	ip, err := netip.ParseAddr(ipStr)
	if err != nil {
		return fmt.Errorf("invalid IP address %s: %w", ipStr, err)
	}

	expiry := uint64(0)
	if ttl > 0 {
		expiry = uint64(time.Now().Add(ttl).UnixNano())
	}

	if ip.Is4() {
		mapObj := m.DynLockList()
		if mapObj == nil {
			return fmt.Errorf("dyn_lock_list not available")
		}

		// Use mapped IPv6 for key
		// ä½¿ç”¨æ˜ å°„çš„ IPv6 ä½œä¸ºé”®
		key := NetXfwIn6Addr{}
		b := ip.As4()
		// ::ffff:a.b.c.d
		key.In6U.U6Addr8[10] = 0xff
		key.In6U.U6Addr8[11] = 0xff
		copy(key.In6U.U6Addr8[12:], b[:])

		val := NetXfwRuleValue{
			Counter:   2, // Deny / æ‹’ç»
			ExpiresAt: expiry,
		}
		if err := mapObj.Update(&key, &val, ebpf.UpdateAny); err != nil {
			return fmt.Errorf("failed to block IPv4 %s: %v", ip, err)
		}
	} else if ip.Is6() {
		mapObj := m.DynLockList()
		if mapObj == nil {
			return fmt.Errorf("dyn_lock_list not available")
		}

		key := NetXfwIn6Addr{}
		b := ip.As16()
		copy(key.In6U.U6Addr8[:], b[:])

		val := NetXfwRuleValue{
			Counter:   2, // Deny / æ‹’ç»
			ExpiresAt: expiry,
		}

		if err := mapObj.Update(&key, &val, ebpf.UpdateAny); err != nil {
			return fmt.Errorf("failed to block IPv6 %s: %v", ip, err)
		}
	}

	log.Printf("ğŸš« Blocked IP %s for %v (expiry: %d)", ip, ttl, expiry)
	return nil
}

// ForceCleanup removes all pinned maps at the specified path.
// ForceCleanup åˆ é™¤æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰å›ºå®š Mapã€‚
func ForceCleanup(path string) error {
	if _, err := os.Stat(path); os.IsNotExist(err) {
		return nil
	}
	return os.RemoveAll(path)
}

// MatchesCapacity checks if the current map capacities match the provided config.
// MatchesCapacity æ£€æŸ¥å½“å‰çš„ Map å®¹é‡æ˜¯å¦ä¸æä¾›çš„é…ç½®åŒ¹é…ã€‚
func (m *Manager) MatchesCapacity(cfg types.CapacityConfig) bool {
	if cfg.LockList > 0 {
		if m.lockList == nil || m.lockList.MaxEntries() != uint32(cfg.LockList) {
			return false
		}
	}
	if cfg.DynLockList > 0 {
		if m.dynLockList == nil || m.dynLockList.MaxEntries() != uint32(cfg.DynLockList) {
			return false
		}
	}
	if cfg.Whitelist > 0 {
		if m.whitelist == nil || m.whitelist.MaxEntries() != uint32(cfg.Whitelist) {
			return false
		}
	}
	if cfg.IPPortRules > 0 {
		if m.ipPortRules == nil || m.ipPortRules.MaxEntries() != uint32(cfg.IPPortRules) {
			return false
		}
	}
	if cfg.Conntrack > 0 {
		if m.conntrackMap == nil || m.conntrackMap.MaxEntries() != uint32(cfg.Conntrack) {
			return false
		}
	}
	if cfg.AllowedPorts > 0 {
		if m.allowedPorts == nil || m.allowedPorts.MaxEntries() != uint32(cfg.AllowedPorts) {
			return false
		}
	}
	return true
}

/**
 * NewManager initializes the BPF objects and removes memory limits.
 * Supports dynamic map capacity adjustment.
 * NewManager åˆå§‹åŒ– BPF å¯¹è±¡å¹¶ç§»é™¤å†…å­˜é™åˆ¶ï¼Œæ”¯æŒåŠ¨æ€è°ƒæ•´ Map å®¹é‡ã€‚
 */
func NewManager(cfg types.CapacityConfig) (*Manager, error) {
	// Remove resource limits for BPF / ç§»é™¤ BPF èµ„æºé™åˆ¶
	if err := rlimit.RemoveMemlock(); err != nil {
		return nil, fmt.Errorf("remove memlock: %w", err)
	}

	// Load BPF collection spec / åŠ è½½ BPF é›†åˆè§„èŒƒ
	spec, err := LoadNetXfw()
	if err != nil {
		return nil, fmt.Errorf("load netxfw spec: %w", err)
	}

	// Dynamic capacity adjustment / åŠ¨æ€è°ƒæ•´å®¹é‡
	if cfg.Conntrack > 0 {
		if m, ok := spec.Maps[config.MapConntrack]; ok {
			m.MaxEntries = uint32(cfg.Conntrack)
		}
	}
	if cfg.LockList > 0 {
		if m, ok := spec.Maps[config.MapLockList]; ok {
			m.MaxEntries = uint32(cfg.LockList)
		}
	}
	if cfg.DynLockList > 0 {
		if m, ok := spec.Maps[config.MapDynLockList]; ok {
			m.MaxEntries = uint32(cfg.DynLockList)
		}
	}
	if cfg.Whitelist > 0 {
		if m, ok := spec.Maps[config.MapWhitelist]; ok {
			m.MaxEntries = uint32(cfg.Whitelist)
		}
	}
	if cfg.IPPortRules > 0 {
		if m, ok := spec.Maps[config.MapIPPortRules]; ok {
			m.MaxEntries = uint32(cfg.IPPortRules)
		}
	}
	if cfg.AllowedPorts > 0 {
		if m, ok := spec.Maps[config.MapAllowedPorts]; ok {
			m.MaxEntries = uint32(cfg.AllowedPorts)
		}
	}

	// Load BPF objects into the kernel / å°† BPF å¯¹è±¡åŠ è½½åˆ°å†…æ ¸
	var objs NetXfwObjects
	if err := spec.LoadAndAssign(&objs, nil); err != nil {
		return nil, fmt.Errorf("load eBPF objects: %w", err)
	}

	manager := &Manager{
		objs:            objs,
		lockList:        objs.LockList,
		dynLockList:     objs.DynLockList,
		whitelist:       objs.Whitelist,
		allowedPorts:    objs.AllowedPorts,
		ipPortRules:     objs.IpPortRules,
		globalConfig:    objs.GlobalConfig,
		dropStats:       objs.DropStats,
		passStats:       objs.PassStats,
		icmpLimitMap:    objs.IcmpLimitMap,
		conntrackMap:    objs.ConntrackMap,
		ratelimitConfig: objs.RatelimitConfig,
		ratelimitState:  objs.RatelimitState,
		jmpTable:        objs.JmpTable,
		dropReasonStats: objs.DropReasonStats,
		passReasonStats: objs.PassReasonStats,
	}

	// Initialize jump table with default protocol handlers
	// åˆå§‹åŒ–è·³è½¬è¡¨ï¼Œå¡«å……é»˜è®¤çš„åè®®å¤„ç†ç¨‹åº
	if objs.XdpIpv4 != nil {
		if err := objs.JmpTable.Update(uint32(ProgIdxIPv4), objs.XdpIpv4, ebpf.UpdateAny); err != nil {
			return nil, fmt.Errorf("failed to update jmp_table with xdp_ipv4: %w", err)
		}
	}
	if objs.XdpIpv6 != nil {
		if err := objs.JmpTable.Update(uint32(ProgIdxIPv6), objs.XdpIpv6, ebpf.UpdateAny); err != nil {
			return nil, fmt.Errorf("failed to update jmp_table with xdp_ipv6: %w", err)
		}
	}

	return manager, nil
}

/**
 * NewManagerFromPins loads a manager using maps already pinned to the filesystem.
 * This is useful for CLI tools that need to interact with a running XDP program.
 * NewManagerFromPins ä½¿ç”¨å·²å›ºå®šåˆ°æ–‡ä»¶ç³»ç»Ÿçš„ Map åŠ è½½ç®¡ç†å™¨ã€‚
 * è¿™å¯¹äºéœ€è¦ä¸æ­£åœ¨è¿è¡Œçš„ XDP ç¨‹åºäº¤äº’çš„ CLI å·¥å…·éå¸¸æœ‰ç”¨ã€‚
 */
func NewManagerFromPins(path string) (*Manager, error) {
	// Remove resource limits for BPF / ç§»é™¤ BPF èµ„æºé™åˆ¶
	if err := rlimit.RemoveMemlock(); err != nil {
		return nil, fmt.Errorf("remove memlock: %w", err)
	}

	// We still need to load objects to get the program, but we will replace maps with pinned ones
	// æˆ‘ä»¬ä»éœ€åŠ è½½å¯¹è±¡ä»¥è·å–ç¨‹åºï¼Œä½†å°†ä½¿ç”¨å›ºå®šçš„ Map æ›¿æ¢å®ƒä»¬
	var objs NetXfwObjects
	if err := LoadNetXfwObjects(&objs, nil); err != nil {
		return nil, fmt.Errorf("load eBPF objects: %w", err)
	}

	m := &Manager{objs: objs}

	var err error
	if m.lockList, err = ebpf.LoadPinnedMap(path+"/lock_list", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned lock_list: %v", err)
		m.lockList = objs.LockList
	}
	if m.dynLockList, err = ebpf.LoadPinnedMap(path+"/dyn_lock_list", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned dyn_lock_list: %v", err)
		m.dynLockList = objs.DynLockList
	}
	if m.whitelist, err = ebpf.LoadPinnedMap(path+"/whitelist", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned whitelist: %v", err)
		m.whitelist = objs.Whitelist
	}
	if m.allowedPorts, err = ebpf.LoadPinnedMap(path+"/allowed_ports", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned allowed_ports: %v", err)
		m.allowedPorts = objs.AllowedPorts
	}
	if m.ipPortRules, err = ebpf.LoadPinnedMap(path+"/ip_port_rules", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned ip_port_rules: %v", err)
		m.ipPortRules = objs.IpPortRules
	}
	if m.globalConfig, err = ebpf.LoadPinnedMap(path+"/global_config", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned global_config: %v", err)
		m.globalConfig = objs.GlobalConfig
	}
	if m.dropStats, err = ebpf.LoadPinnedMap(path+"/drop_stats", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned drop_stats: %v", err)
		m.dropStats = objs.DropStats
	}
	if m.dropReasonStats, err = ebpf.LoadPinnedMap(path+"/drop_reason_stats", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned drop_reason_stats: %v", err)
		m.dropReasonStats = objs.DropReasonStats
	}
	if m.passStats, err = ebpf.LoadPinnedMap(path+"/pass_stats", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned pass_stats: %v", err)
		m.passStats = objs.PassStats
	}
	if m.passReasonStats, err = ebpf.LoadPinnedMap(path+"/pass_reason_stats", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned pass_reason_stats: %v", err)
		m.passReasonStats = objs.PassReasonStats
	}
	if m.icmpLimitMap, err = ebpf.LoadPinnedMap(path+"/icmp_limit_map", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned icmp_limit_map: %v", err)
		m.icmpLimitMap = objs.IcmpLimitMap
	}
	if m.conntrackMap, err = ebpf.LoadPinnedMap(path+"/conntrack_map", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned conntrack_map: %v", err)
		m.conntrackMap = objs.ConntrackMap
	}
	if m.ratelimitConfig, err = ebpf.LoadPinnedMap(path+"/ratelimit_config", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned ratelimit_config: %v", err)
		m.ratelimitConfig = objs.RatelimitConfig
	}
	if m.ratelimitState, err = ebpf.LoadPinnedMap(path+"/ratelimit_state", nil); err != nil {
		log.Printf("âš ï¸  Could not load pinned ratelimit_state: %v", err)
		m.ratelimitState = objs.RatelimitState
	}

	return m, nil
}

/**
 * Attach mounts the XDP program to the specified network interfaces.
 * It tries Offload mode, then Native mode, and finally Generic mode as fallbacks.
 * The XDP program is attached using link.XDP_FLAGS_REPLACE or similar to ensure it stays in kernel.
 * Attach å°† XDP ç¨‹åºæŒ‚è½½åˆ°æŒ‡å®šçš„ç½‘ç»œæ¥å£ã€‚
 * å®ƒå°è¯• Offload æ¨¡å¼ï¼Œç„¶åæ˜¯ Native æ¨¡å¼ï¼Œæœ€åæ˜¯ Generic æ¨¡å¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆã€‚
 * XDP ç¨‹åºä½¿ç”¨ link.XDP_FLAGS_REPLACE æˆ–ç±»ä¼¼æ–¹å¼æŒ‚è½½ï¼Œä»¥ç¡®ä¿å…¶ç•™åœ¨å†…æ ¸ä¸­ã€‚
 */
func (m *Manager) Attach(interfaces []string) error {
	for _, name := range interfaces {
		iface, err := net.InterfaceByName(name)
		if err != nil {
			log.Printf("Skip interface %s: %v", name, err)
			continue
		}

		// Try to atomic update existing XDP link
		// å°è¯•åŸå­æ›´æ–°ç°æœ‰çš„ XDP é“¾æ¥
		linkPath := filepath.Join(config.GetPinPath(), fmt.Sprintf("link_%s", name))
		var attached bool

		if l, err := link.LoadPinnedLink(linkPath, nil); err == nil {
			if err := l.Update(m.objs.XdpFirewall); err == nil {
				log.Printf("âœ… Atomic Reload: Updated XDP program on %s", name)
				l.Close()
				attached = true
			} else {
				log.Printf("âš ï¸  Atomic Reload failed on %s: %v. Fallback to detach/attach.", name, err)
				l.Close()
				_ = os.Remove(linkPath) // Force remove to allow re-attach / å¼ºåˆ¶åˆ é™¤ä»¥å…è®¸é‡æ–°æŒ‚è½½
			}
		}

		if !attached {
			modes := []struct {
				name string
				flag link.XDPAttachFlags
			}{
				{"Offload", link.XDPOffloadMode},
				{"Native", link.XDPDriverMode},
				{"Generic", link.XDPGenericMode},
			}

			for _, mode := range modes {
				// Using Pin-less link or simply not storing the link object if we want it to persist.
				// However, in cilium/ebpf, if the link object is closed, the program is detached.
				// To keep it persistent, we need to PIN the link or use Raw attach.
				// ä½¿ç”¨ä¸å¸¦å›ºå®šç‚¹çš„é“¾æ¥ï¼Œæˆ–è€…å¦‚æœæˆ‘ä»¬å¸Œæœ›å®ƒæŒä¹…åŒ–ï¼Œåˆ™æ ¹æœ¬ä¸å­˜å‚¨é“¾æ¥å¯¹è±¡ã€‚
				// ç„¶è€Œï¼Œåœ¨ cilium/ebpf ä¸­ï¼Œå¦‚æœé“¾æ¥å¯¹è±¡è¢«å…³é—­ï¼Œç¨‹åºå°†è¢«å¸è½½ã€‚
				// ä¸ºäº†ä¿æŒæŒä¹…æ€§ï¼Œæˆ‘ä»¬éœ€è¦å›ºå®šï¼ˆPINï¼‰é“¾æ¥æˆ–ä½¿ç”¨åŸå§‹æŒ‚è½½ã€‚
				l, err := link.AttachXDP(link.XDPOptions{
					Program:   m.objs.XdpFirewall,
					Interface: iface.Index,
					Flags:     mode.flag,
				})

				if err == nil {
					// Pin the link to filesystem to make it persistent after process exit
					// å°†é“¾æ¥å›ºå®šåˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œä½¿å…¶åœ¨è¿›ç¨‹é€€å‡ºåä¿æŒæŒä¹…
					_ = os.Remove(linkPath) // Remove old link pin if exists / å¦‚æœå­˜åœ¨æ—§çš„é“¾æ¥å›ºå®šç‚¹ï¼Œåˆ™å°†å…¶åˆ é™¤
					if err := l.Pin(linkPath); err != nil {
						log.Printf("âš ï¸  Failed to pin link on %s: %v", name, err)
						l.Close()
						continue
					}
					log.Printf("âœ… Attached XDP on %s (Mode: %s) and pinned link", name, mode.name)
					attached = true
					break
				}
				log.Printf("âš ï¸  Failed to attach XDP on %s using %s mode: %v", name, mode.name, err)
			}
		}

		// Attach TC for egress tracking (required for Conntrack)
		// é™„åŠ  TC ç”¨äºå‡ºå£è¿½è¸ªï¼ˆè¿æ¥è·Ÿè¸ª Conntrack æ‰€éœ€ï¼‰
		// 1. Ensure clsact qdisc exists / ç¡®ä¿ clsact qdisc å­˜åœ¨
		_ = exec.Command("tc", "qdisc", "add", "dev", name, "clsact").Run()

		// 2. Attach TC program / æŒ‚è½½ TC ç¨‹åº
		tcLinkPath := filepath.Join(config.GetPinPath(), fmt.Sprintf("tc_link_%s", name))
		var tcAttached bool

		// Try atomic update for TC / å°è¯•åŸå­æ›´æ–° TC
		if tl, err := link.LoadPinnedLink(tcLinkPath, nil); err == nil {
			if err := tl.Update(m.objs.TcEgress); err == nil {
				log.Printf("âœ… Atomic Reload: Updated TC Egress on %s", name)
				tl.Close()
				tcAttached = true
			} else {
				tl.Close()
				_ = os.Remove(tcLinkPath)
			}
		}

		if !tcAttached {
			tcLink, err := link.AttachTCX(link.TCXOptions{
				Program:   m.objs.TcEgress,
				Interface: iface.Index,
				Attach:    ebpf.AttachTCXEgress,
			})
			if err == nil {
				_ = os.Remove(tcLinkPath)
				if err := tcLink.Pin(tcLinkPath); err != nil {
					log.Printf("âš ï¸  Failed to pin TC link on %s: %v", name, err)
					tcLink.Close()
				} else {
					log.Printf("âœ… Attached TC Egress on %s and pinned link", name)
				}
			} else {
				log.Printf("âš ï¸  Failed to attach TC Egress on %s: %v (Conntrack will not work for this interface)", name, err)
			}
		}

		if !attached {
			log.Printf("âŒ Failed to attach XDP on %s with any mode", name)
		}
	}
	return nil
}

/**
 * Detach removes the XDP program from the specified network interfaces by unpinning and closing links.
 * Detach é€šè¿‡å–æ¶ˆå›ºå®šå’Œå…³é—­é“¾æ¥ï¼Œä»æŒ‡å®šçš„ç½‘ç»œæ¥å£ç§»é™¤ XDP ç¨‹åºã€‚
 */
func (m *Manager) Detach(interfaces []string) error {
	for _, name := range interfaces {
		linkPath := filepath.Join(config.GetPinPath(), fmt.Sprintf("link_%s", name))
		l, err := link.LoadPinnedLink(linkPath, nil)
		if err != nil {
			log.Printf("âš ï¸  No pinned link found for %s, trying manual detach...", name)
			// Fallback: try to detach using interface index if possible,
			// but usually unpinning the persistent link is enough.
			// å¤‡é€‰æ–¹æ¡ˆï¼šå¦‚æœå¯èƒ½ï¼Œå°è¯•ä½¿ç”¨æ¥å£ç´¢å¼•è¿›è¡Œåˆ†ç¦»ï¼Œä½†é€šå¸¸å–æ¶ˆå›ºå®šæŒä¹…é“¾æ¥å°±è¶³å¤Ÿäº†ã€‚
			continue
		}
		if err := l.Close(); err != nil {
			log.Printf("âŒ Failed to close link for %s: %v", name, err)
		} else {
			_ = os.Remove(linkPath)
			log.Printf("âœ… Detached XDP from %s", name)
		}

		// Detach TC link / åˆ†ç¦» TC é“¾æ¥
		tcLinkPath := filepath.Join(config.GetPinPath(), fmt.Sprintf("tc_link_%s", name))
		if tl, err := link.LoadPinnedLink(tcLinkPath, nil); err == nil {
			if err := tl.Close(); err != nil {
				log.Printf("âŒ Failed to close TC link for %s: %v", name, err)
			} else {
				_ = os.Remove(tcLinkPath)
				log.Printf("âœ… Detached TC Egress from %s", name)
			}
		}
	}
	return nil
}

/**
 * GetAttachedInterfaces returns a list of interfaces that currently have XDP/TC programs attached
 * by looking for pinned links in the default pin path.
 * GetAttachedInterfaces é€šè¿‡åœ¨é»˜è®¤å›ºå®šè·¯å¾„ä¸­æŸ¥æ‰¾å›ºå®šé“¾æ¥ï¼Œè¿”å›å½“å‰æŒ‚è½½äº† XDP/TC ç¨‹åºçš„æ¥å£åˆ—è¡¨ã€‚
 */
func GetAttachedInterfaces(pinPath string) ([]string, error) {
	entries, err := os.ReadDir(pinPath)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, nil
		}
		return nil, err
	}

	var interfaces []string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasPrefix(entry.Name(), "link_") {
			iface := strings.TrimPrefix(entry.Name(), "link_")
			interfaces = append(interfaces, iface)
		}
	}
	return interfaces, nil
}

/**
 * MigrateState copies all entries from an old manager's maps to this manager's maps.
 * This is used for hot-reloading to preserve conntrack state and rules.
 * MigrateState å°†æ—§ç®¡ç†å™¨çš„ Map æ¡ç›®å¤åˆ¶åˆ°æ­¤ç®¡ç†å™¨çš„ Map ä¸­ï¼Œç”¨äºçƒ­åŠ è½½ä»¥ä¿ç•™çŠ¶æ€ã€‚
 */
func (m *Manager) MigrateState(old *Manager) error {
	// Migrate Conntrack / è¿ç§»è¿æ¥è·Ÿè¸ª (Conntrack)
	if old.conntrackMap != nil && m.conntrackMap != nil {
		var key NetXfwCtKey
		var val NetXfwCtValue
		iter := old.conntrackMap.Iterate()
		for iter.Next(&key, &val) {
			m.conntrackMap.Put(&key, &val)
		}
	}

	// Migrate Lock List / è¿ç§»é”å®šåˆ—è¡¨ (Lock List)
	if old.lockList != nil && m.lockList != nil {
		var key NetXfwLpmKey
		var val NetXfwRuleValue
		iter := old.lockList.Iterate()
		for iter.Next(&key, &val) {
			m.lockList.Put(&key, &val)
		}
	}

	// Migrate Dynamic Lock List / è¿ç§»åŠ¨æ€é”å®šåˆ—è¡¨ (Dynamic Lock List)
	if old.dynLockList != nil && m.dynLockList != nil {
		var key NetXfwLpmKey
		var val NetXfwRuleValue
		iter := old.dynLockList.Iterate()
		for iter.Next(&key, &val) {
			m.dynLockList.Put(&key, &val)
		}
	}

	// Migrate Whitelist / è¿ç§»ç™½åå• (Whitelist)
	if old.whitelist != nil && m.whitelist != nil {
		var key NetXfwLpmKey
		var val NetXfwRuleValue
		iter := old.whitelist.Iterate()
		for iter.Next(&key, &val) {
			m.whitelist.Put(&key, &val)
		}
	}

	// Migrate IP+Port Rules / è¿ç§» IP+ç«¯å£è§„åˆ™ (IP+Port Rules)
	if old.ipPortRules != nil && m.ipPortRules != nil {
		var key NetXfwLpmIpPortKey
		var val NetXfwRuleValue
		iter := old.ipPortRules.Iterate()
		for iter.Next(&key, &val) {
			m.ipPortRules.Put(&key, &val)
		}
	}

	// Migrate Allowed Ports (PERCPU HASH) / è¿ç§»å…è®¸ç«¯å£ (Allowed Ports)
	if old.allowedPorts != nil && m.allowedPorts != nil {
		var key uint16
		numCPU, _ := ebpf.PossibleCPU()
		val := make([]NetXfwRuleValue, numCPU)
		iter := old.allowedPorts.Iterate()
		for iter.Next(&key, &val) {
			m.allowedPorts.Put(&key, &val)
		}
	}

	// Migrate Rate Limit Config (LPM TRIE) / è¿ç§»é€Ÿç‡é™åˆ¶é…ç½® (Rate Limit Config)
	if old.ratelimitConfig != nil && m.ratelimitConfig != nil {
		var key NetXfwLpmKey
		var val NetXfwRatelimitConf
		iter := old.ratelimitConfig.Iterate()
		for iter.Next(&key, &val) {
			m.ratelimitConfig.Put(&key, &val)
		}
	}

	// Migrate Rate Limit State (LRU HASH) / è¿ç§»é€Ÿç‡é™åˆ¶çŠ¶æ€ (Rate Limit State)
	if old.ratelimitState != nil && m.ratelimitState != nil {
		var key NetXfwIn6Addr
		var val NetXfwRatelimitStats
		iter := old.ratelimitState.Iterate()
		for iter.Next(&key, &val) {
			m.ratelimitState.Put(&key, &val)
		}
	}

	return nil
}

/**
 * LoadPlugin loads a BPF program from an ELF file and inserts it into the jump table.
 * LoadPlugin ä» ELF æ–‡ä»¶åŠ è½½ BPF ç¨‹åºå¹¶å°†å…¶æ’å…¥è·³è½¬è¡¨ã€‚
 */
func (m *Manager) LoadPlugin(elfPath string, index int) error {
	if index < ProgIdxPluginStart || index > ProgIdxPluginEnd {
		return fmt.Errorf("invalid plugin index: %d (must be between %d and %d)",
			index, ProgIdxPluginStart, ProgIdxPluginEnd)
	}

	spec, err := ebpf.LoadCollectionSpec(elfPath)
	if err != nil {
		return fmt.Errorf("load plugin spec: %w", err)
	}

	// For simplicity, we assume the first XDP program found is the plugin
	// ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å‡è®¾æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ª XDP ç¨‹åºå°±æ˜¯æ’ä»¶
	var progSpec *ebpf.ProgramSpec
	for _, p := range spec.Programs {
		if p.Type == ebpf.XDP {
			progSpec = p
			break
		}
	}

	if progSpec == nil {
		return fmt.Errorf("no XDP program found in plugin: %s", elfPath)
	}

	prog, err := ebpf.NewProgram(progSpec)
	if err != nil {
		return fmt.Errorf("load plugin program: %w", err)
	}
	// Note: We don't close the program here as it needs to stay in the jmpTable
	// æ³¨æ„ï¼šæˆ‘ä»¬åœ¨è¿™é‡Œä¸å…³é—­ç¨‹åºï¼Œå› ä¸ºå®ƒéœ€è¦ç•™åœ¨ jmpTable ä¸­

	if err := m.jmpTable.Update(uint32(index), prog, ebpf.UpdateAny); err != nil {
		prog.Close()
		return fmt.Errorf("failed to update jmp_table with plugin: %w", err)
	}

	log.Printf("âœ… Plugin loaded: %s at index %d", elfPath, index)
	return nil
}

/**
 * RemovePlugin removes a plugin from the jump table.
 * RemovePlugin ä»è·³è½¬è¡¨ä¸­ç§»é™¤æ’ä»¶ã€‚
 */
func (m *Manager) RemovePlugin(index int) error {
	if index < ProgIdxPluginStart || index > ProgIdxPluginEnd {
		return fmt.Errorf("invalid plugin index: %d", index)
	}

	if err := m.jmpTable.Delete(uint32(index)); err != nil {
		return fmt.Errorf("failed to remove plugin from jmp_table: %w", err)
	}

	log.Printf("âœ… Plugin removed from index %d", index)
	return nil
}

/**
 * Close releases all BPF resources.
 * Note: Persistent links are NOT closed here to allow them to stay in kernel.
 * Close é‡Šæ”¾æ‰€æœ‰ BPF èµ„æºã€‚
 * æ³¨æ„ï¼šæ­¤å¤„ä¸å…³é—­æŒä¹…é“¾æ¥ï¼Œä»¥å…è®¸å®ƒä»¬ä¿ç•™åœ¨å†…æ ¸ä¸­ã€‚
 */
func (m *Manager) Close() {
	m.objs.Close()
	// We no longer automatically close links here to keep them persistent.
	// Links are now pinned and should be managed via Detach or manually.
	// æˆ‘ä»¬ä¸å†åœ¨æ­¤å¤„è‡ªåŠ¨å…³é—­é“¾æ¥ï¼Œä»¥ä¿æŒå…¶æŒä¹…æ€§ã€‚
	// é“¾æ¥ç°åœ¨å·²è¢«å›ºå®šï¼Œåº”é€šè¿‡ Detach æˆ–æ‰‹åŠ¨ç®¡ç†ã€‚
}

/**
 * Pin saves maps to the filesystem for persistence and external access.
 * Pin å°† Map ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿä»¥è¿›è¡ŒæŒä¹…åŒ–å’Œå¤–éƒ¨è®¿é—®ã€‚
 */
func (m *Manager) Pin(path string) error {
	if err := os.MkdirAll(path, 0755); err != nil {
		return err
	}

	pinMap := func(ebpfMap *ebpf.Map, name string) {
		if ebpfMap == nil {
			return
		}
		p := path + "/" + name
		_ = os.Remove(p) // Ensure old pin is removed / ç¡®ä¿æ—§çš„å›ºå®šç‚¹è¢«ç§»é™¤
		if err := ebpfMap.Pin(p); err != nil {
			log.Printf("âš ï¸  Failed to pin %s: %v", name, err)
		}
	}

	pinMap(m.lockList, config.MapLockList)
	pinMap(m.dynLockList, config.MapDynLockList)
	pinMap(m.whitelist, config.MapWhitelist)
	pinMap(m.allowedPorts, config.MapAllowedPorts)
	pinMap(m.ipPortRules, config.MapIPPortRules)
	pinMap(m.globalConfig, config.MapGlobalConfig)
	pinMap(m.dropStats, config.MapDropStats)
	pinMap(m.dropReasonStats, config.MapDropReasonStats)
	pinMap(m.icmpLimitMap, config.MapICMPLimit)
	pinMap(m.conntrackMap, config.MapConntrack)
	pinMap(m.passStats, config.MapPassStats)
	pinMap(m.passReasonStats, config.MapPassReasonStats)
	pinMap(m.ratelimitConfig, config.MapRatelimitConfig)
	pinMap(m.ratelimitState, config.MapRatelimitState)

	return nil
}

// Unpin removes maps from the filesystem.
// Unpin ä»æ–‡ä»¶ç³»ç»Ÿä¸­ç§»é™¤ Mapã€‚
func (m *Manager) Unpin(path string) error {
	_ = m.lockList.Unpin()
	if m.dynLockList != nil {
		_ = m.dynLockList.Unpin()
	}
	_ = m.whitelist.Unpin()
	_ = m.allowedPorts.Unpin()
	_ = m.ipPortRules.Unpin()
	_ = m.globalConfig.Unpin()
	_ = m.dropStats.Unpin()
	if m.dropReasonStats != nil {
		_ = m.dropReasonStats.Unpin()
	}
	_ = m.icmpLimitMap.Unpin()
	_ = m.conntrackMap.Unpin()
	if m.passStats != nil {
		_ = m.passStats.Unpin()
	}
	_ = m.ratelimitConfig.Unpin()
	_ = m.ratelimitState.Unpin()
	return os.RemoveAll(path)
}
