package types

import (
	"bytes"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"sort"
	"sync"
	"time"

	"github.com/livp123/netxfw/internal/utils/fileutil"
	"gopkg.in/yaml.v3"
)

// ConfigMu protects concurrent access to the configuration file.
// ConfigMu ä¿æŠ¤å¯¹é…ç½®æ–‡ä»¶çš„å¹¶å‘è®¿é—®ã€‚
var ConfigMu sync.RWMutex

// DefaultConfigTemplate defines the default configuration file structure with bilingual comments.
// This template is used to initialize new config files and to repair missing sections in existing files
// while preserving documentation.
const DefaultConfigTemplate = `# NetXFW Configuration File / NetXFW é…ç½®æ–‡ä»¶
#

# Cluster Configuration / é›†ç¾¤é…ç½®
# Default cluster config file path / é»˜è®¤é›†ç¾¤é…ç½®æ–‡ä»¶è·¯å¾„
cluster:
  enabled: false
  configpath: "cluster.yaml"

# Base Configuration / åŸºç¡€é…ç½®
base:
  # Default Deny Policy: If true, all traffic not explicitly allowed is dropped.
  # é»˜è®¤æ‹’ç»ç­–ç•¥ï¼šå¦‚æœä¸º trueï¼Œæ‰€æœ‰æœªæ˜¾å¼å…è®¸çš„æµé‡å°†è¢«ä¸¢å¼ƒã€‚
  default_deny: true

  # Allow Return Traffic: Stateless check (ACK + Port range).
  # å…è®¸å›ç¨‹æµé‡ï¼šæ— çŠ¶æ€æ£€æŸ¥ï¼ˆACK + ç«¯å£èŒƒå›´ï¼‰ã€‚
  allow_return_traffic: true

  # Allow ICMP: Allow Ping and other ICMP messages.
  # å…è®¸ ICMPï¼šå…è®¸ Ping å’Œå…¶ä»– ICMP æ¶ˆæ¯ã€‚
  allow_icmp: true

  # Interfaces: Network interfaces to attach XDP to.
  # If empty, all physical interfaces will be auto-detected.
  # æ¥å£ï¼šè¦æŒ‚è½½ XDP çš„ç½‘ç»œæ¥å£ã€‚
  # å¦‚æœä¸ºç©ºï¼Œå°†è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ç‰©ç†æ¥å£ã€‚
  interfaces: []

  # Enable AF_XDP: Enable high-performance packet redirection to userspace.
  # å¯ç”¨ AF_XDPï¼šå¯ç”¨é«˜æ€§èƒ½æ•°æ®åŒ…é‡å®šå‘åˆ°ç”¨æˆ·ç©ºé—´ã€‚
  enable_af_xdp: false

  # BPF Pin Path: Path to pin BPF maps. Defaults to /sys/fs/bpf/netxfw if empty.
  # BPF å›ºå®šè·¯å¾„ï¼šå›ºå®š BPF Map çš„è·¯å¾„ã€‚å¦‚æœä¸ºç©ºï¼Œé»˜è®¤ä¸º /sys/fs/bpf/netxfwã€‚
  bpf_pin_path: ""

  # Strict Protocol Validation: Drop malformed packets.
  # ä¸¥æ ¼åè®®éªŒè¯ï¼šä¸¢å¼ƒç•¸å½¢æ•°æ®åŒ…ã€‚
  strict_protocol: false

  # Drop IP Fragments: Prevent fragmentation attacks.
  # ä¸¢å¼ƒ IP åˆ†ç‰‡ï¼šé˜²æ­¢åˆ†ç‰‡æ”»å‡»ã€‚
  drop_fragments: false

  # Strict TCP Validation: Check TCP flags and sequence numbers.
  # ä¸¥æ ¼ TCP éªŒè¯ï¼šæ£€æŸ¥ TCP æ ‡å¿—å’Œåºåˆ—å·ã€‚
  strict_tcp: false

  # SYN Rate Limit: Limit SYN packets to prevent flood attacks.
  # SYN é€Ÿç‡é™åˆ¶ï¼šé™åˆ¶ SYN æ•°æ®åŒ…ä»¥é˜²æ­¢æ³›æ´ªæ”»å‡»ã€‚
  syn_limit: false

  # Bogon Filter: Drop packets from reserved/private IP ranges on public interfaces.
  # Bogon è¿‡æ»¤ï¼šä¸¢å¼ƒæ¥è‡ªä¿ç•™/ç§æœ‰ IP èŒƒå›´çš„æ•°æ®åŒ…ã€‚
  bogon_filter: false

  # ICMP Rate Limit (pps) / ICMP é€Ÿç‡é™åˆ¶ (æ¯ç§’åŒ…æ•°)
  icmp_rate: 10

  # ICMP Burst Size / ICMP çªå‘å¤§å°
  icmp_burst: 50

  # Whitelist: Global allowed IPs/CIDRs.
  # ç™½åå•ï¼šå…¨å±€å…è®¸çš„ IP/CIDRã€‚
  whitelist: []

  # Lock List File: Persistence file for blocked IPs.
  # é”å®šåˆ—è¡¨æ–‡ä»¶ï¼šè¢«å°ç¦ IP çš„æŒä¹…åŒ–æ–‡ä»¶ã€‚
  lock_list_file: "/etc/netxfw/lock_list.txt"

  # Lock List Binary: Binary format for fast loading (optional).
  # é”å®šåˆ—è¡¨äºŒè¿›åˆ¶æ–‡ä»¶ï¼šç”¨äºå¿«é€ŸåŠ è½½çš„äºŒè¿›åˆ¶æ ¼å¼ï¼ˆå¯é€‰ï¼‰ã€‚
  lock_list_binary: ""

  # Lock List Merge Threshold: If > 0, merge IPs into subnets if count >= threshold.
  # é”å®šåˆ—è¡¨åˆå¹¶é˜ˆå€¼ï¼šå¦‚æœ > 0ï¼Œå½“æ•°é‡ >= é˜ˆå€¼æ—¶å°† IP åˆå¹¶ä¸ºå­ç½‘ã€‚
  lock_list_merge_threshold: 0

  # Lock List IPv4 Mask: Target mask for IPv4 merging (default 24).
  # é”å®šåˆ—è¡¨ IPv4 æ©ç ï¼šIPv4 åˆå¹¶çš„ç›®æ ‡æ©ç ï¼ˆé»˜è®¤ 24ï¼‰ã€‚
  lock_list_v4_mask: 24

  # Lock List IPv6 Mask: Target mask for IPv6 merging (default 64).
  # é”å®šåˆ—è¡¨ IPv6 æ©ç ï¼šIPv6 åˆå¹¶çš„ç›®æ ‡æ©ç ï¼ˆé»˜è®¤ 64ï¼‰ã€‚
  lock_list_v6_mask: 64

  # Enable Expiry: Automatically clean up old rules.
  # å¯ç”¨è¿‡æœŸï¼šè‡ªåŠ¨æ¸…ç†æ—§è§„åˆ™ã€‚
  enable_expiry: true

  # Cleanup Interval: How often to run cleanup (e.g., "1m", "1h").
  # æ¸…ç†é—´éš”ï¼šå¤šä¹…è¿è¡Œä¸€æ¬¡æ¸…ç†ï¼ˆä¾‹å¦‚ "1m", "1h"ï¼‰ã€‚
  cleanup_interval: "1m"

  # Persist Rules: Save runtime rule changes to disk.
  # æŒä¹…åŒ–è§„åˆ™ï¼šå°†è¿è¡Œæ—¶è§„åˆ™æ›´æ”¹ä¿å­˜åˆ°ç£ç›˜ã€‚
  persist_rules: true

  # Enable Pprof: Enable Go performance profiling.
  # å¯ç”¨ Pprofï¼šå¯ç”¨ Go æ€§èƒ½åˆ†æã€‚
  enable_pprof: false

  # Pprof Port: Port for pprof server (localhost only).
  # Pprof ç«¯å£ï¼špprof æœåŠ¡å™¨ç«¯å£ï¼ˆä»…é™æœ¬åœ°ä¸»æœºï¼‰ã€‚
  pprof_port: 6060

# Web Server Configuration / Web æœåŠ¡å™¨é…ç½®
web:
  enabled: false
  port: 11811
  token: ""

# Metrics Configuration / ç›‘æ§æŒ‡æ ‡é…ç½®
# When metrics.enabled = false, metrics are served via web server at /metrics path
# å½“ metrics.enabled = false æ—¶ï¼ŒæŒ‡æ ‡é€šè¿‡ web æœåŠ¡å™¨çš„ /metrics è·¯å¾„æä¾›
metrics:
  enabled: false
  server_enabled: false
  port: 11812
  push_enabled: false
  push_gateway_addr: ""
  push_interval: "15s"
  textfile_enabled: false
  textfile_path: ""


# Port Configuration / ç«¯å£é…ç½®
port:
  # Allowed Ports: List of allowed destination ports (TCP/UDP).
  # å…è®¸ç«¯å£ï¼šå…è®¸çš„ç›®æ ‡ç«¯å£åˆ—è¡¨ (TCP/UDP)ã€‚
  allowed_ports: []
  
  # IP-Port Rules: Specific rules for IP+Port combinations.
  # IP-ç«¯å£è§„åˆ™ï¼šé’ˆå¯¹ IP+ç«¯å£ç»„åˆçš„ç‰¹å®šè§„åˆ™ã€‚
  ip_port_rules: []
  # Example / ç¤ºä¾‹:
  # - ip: "192.168.1.100"
  #   port: 80
  #   action: 1  # 1: Allow, 2: Deny

# Conntrack Configuration / è¿æ¥è·Ÿè¸ªé…ç½®
conntrack:
  enabled: true
  max_entries: 100000
  tcp_timeout: "1h"
  udp_timeout: "5m"

# Rate Limit Configuration / é€Ÿç‡é™åˆ¶é…ç½®
rate_limit:
  enabled: true
  auto_block: true
  # Auto Block Expiry: Duration to block IPs that exceed limits.
  # è‡ªåŠ¨å°ç¦è¿‡æœŸæ—¶é—´ï¼šè¶…è¿‡é™åˆ¶çš„ IP çš„å°ç¦æŒç»­æ—¶é—´ã€‚
  auto_block_expiry: "10m"
  rules: []
  # Example / ç¤ºä¾‹:
  # - ip: "10.0.0.0/24"
  #   rate: 1000
  #   burst: 2000

# Log Engine Configuration / æ—¥å¿—å¼•æ“é…ç½®
log_engine:
  enabled: false
  workers: 4
  
  rules: []
  # Example 1: SSH Brute Force Protection / ç¤ºä¾‹ 1ï¼šSSH é˜²çˆ†ç ´
  # - id: "ssh_brute_force"
  #   path: "/var/log/auth.log"
  #   tail_position: "end" # "start", "end", "offset" (default: end)
  #   # Expression Syntax / è¡¨è¾¾å¼è¯­æ³•:
  #   # log("pattern")  -> Case-insensitive match / ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
  #   # logE("pattern") -> Case-sensitive match (Exact) / åŒºåˆ†å¤§å°å†™åŒ¹é… (ç²¾ç¡®)
  #   # time(seconds)   -> Count occurrences in last N seconds / è¿‡å» N ç§’å†…çš„è®¡æ•°
  #   expression: 'log("Failed password") && log("root") && time(60) > 5'
  #   action: "block"   # Actions: 0="log", 1="block" (dynamic), 2="static" (permanent)
  #   ttl: "10m"        # Block duration / å°ç¦æ—¶é•¿

  # Example 2: Nginx 404 Flood / ç¤ºä¾‹ 2ï¼šNginx 404 æ´ªæ°´æ”»å‡»
  # - id: "nginx_404_flood"
  #   path: "/var/log/nginx/access.log"
  #   expression: 'log(" 404 ") && time(10) > 20'
  #   action: "block"
  #   ttl: "1h"

# Capacity Configuration / å®¹é‡é…ç½®
# Adjust these based on your system memory and requirements.
# æ ¹æ®æ‚¨çš„ç³»ç»Ÿå†…å­˜å’Œéœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚
capacity:
  lock_list: 2000000
  dyn_lock_list: 2000000
  whitelist: 65536
  ip_port_rules: 65536
  allowed_ports: 1024

# Logging Configuration / æ—¥å¿—é…ç½®
logging:
  enabled: false
  # Log file path / æ—¥å¿—æ–‡ä»¶è·¯å¾„
  path: "/var/log/netxfw/agent.log"
  # Max size in MB before rotation / è½®è½¬å‰çš„æœ€å¤§å¤§å° (MB)
  max_size: 10
  # Max number of old files to keep / ä¿ç•™çš„æ—§æ–‡ä»¶æœ€å¤§æ•°é‡
  max_backups: 3
  # Max number of days to keep old files / ä¿ç•™æ—§æ–‡ä»¶çš„æœ€å¤§å¤©æ•°
  max_age: 30
  # Whether to compress old files / æ˜¯å¦å‹ç¼©æ—§æ–‡ä»¶
  compress: true
`

// GlobalConfig represents the top-level configuration structure.
// GlobalConfig è¡¨ç¤ºé¡¶çº§é…ç½®ç»“æ„ã€‚
type GlobalConfig struct {
	Cluster   ClusterConfig   `yaml:"cluster"`
	Base      BaseConfig      `yaml:"base"`
	Web       WebConfig       `yaml:"web"`
	Metrics   MetricsConfig   `yaml:"metrics"`
	Port      PortConfig      `yaml:"port"`
	Conntrack ConntrackConfig `yaml:"conntrack"`
	RateLimit RateLimitConfig `yaml:"rate_limit"`
	LogEngine LogEngineConfig `yaml:"log_engine"`
	Capacity  CapacityConfig  `yaml:"capacity"`
	Logging   LoggingConfig   `yaml:"logging"`
	AI        AIConfig        `yaml:"ai"`
	MCP       MCPConfig       `yaml:"mcp"`
}

// LoggingConfig defines the configuration for logging.
// LoggingConfig å®šä¹‰æ—¥å¿—é…ç½®ã€‚
type LoggingConfig struct {
	Enabled bool   `yaml:"enabled"`
	Level   string `yaml:"level"` // Log level (debug, info, warn, error)
	// Level: æ—¥å¿—çº§åˆ«ï¼ˆdebug, info, warn, errorï¼‰
	Path string `yaml:"path"` // Log file path
	// Path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
	MaxSize int `yaml:"max_size"` // Max size in MB before rotation
	// MaxSize: è½®è½¬å‰çš„æœ€å¤§å¤§å°ï¼ˆMBï¼‰
	MaxBackups int `yaml:"max_backups"` // Max number of old files to keep
	// MaxBackups: ä¿ç•™çš„æ—§æ–‡ä»¶æœ€å¤§æ•°é‡
	MaxAge int `yaml:"max_age"` // Max number of days to keep old files
	// MaxAge: ä¿ç•™æ—§æ–‡ä»¶çš„æœ€å¤§å¤©æ•°
	Compress bool `yaml:"compress"` // Whether to compress old files
	// Compress: æ˜¯å¦å‹ç¼©æ—§æ–‡ä»¶
}

// LogEngineConfig defines the configuration for the log engine.
// LogEngineConfig å®šä¹‰æ—¥å¿—å¼•æ“é…ç½®ã€‚
type LogEngineConfig struct {
	Enabled   bool `yaml:"enabled"`
	Workers   int  `yaml:"workers"`
	MaxWindow int  `yaml:"max_window"` // Max history window in seconds (default 3600)
	// MaxWindow: æœ€å¤§å†å²çª—å£ï¼ˆç§’ï¼Œé»˜è®¤ 3600ï¼‰
	Rules []LogEngineRule `yaml:"rules"`
}

// LogEngineRule defines a rule for the log engine.
// LogEngineRule å®šä¹‰æ—¥å¿—å¼•æ“è§„åˆ™ã€‚
type LogEngineRule struct {
	ID   string `yaml:"id"`
	Path string `yaml:"path"` // Optional: File path pattern (glob or substring)
	// Path: å¯é€‰ï¼šæ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼ˆglob æˆ–å­å­—ç¬¦ä¸²ï¼‰

	// Tail Position: "start", "end" (default), "offset"
	// è¯»å–ä½ç½®ï¼š"start" (ä»å¤´å¼€å§‹), "end" (ä»æœ«å°¾å¼€å§‹), "offset" (ä»ä¸Šæ¬¡è®°å½•ä½ç½®å¼€å§‹)
	TailPosition string `yaml:"tail_position"`

	Expression string `yaml:"expression"`
	Action     string `yaml:"action"` // "block", "log"
	// Action: æ‰§è¡ŒåŠ¨ä½œ ("block", "log")

	// Simplified Configuration (alternative to Expression)
	// ç®€åŒ–é…ç½®ï¼ˆExpression çš„æ›¿ä»£æ–¹æ¡ˆï¼‰
	Keywords []string `yaml:"keywords"` // Deprecated: Use Contains instead (AND logic)
	// Keywords: å·²å¼ƒç”¨ï¼šè¯·æ”¹ç”¨ Contains (AND é€»è¾‘)
	Contains []string `yaml:"contains"` // AND logic: Must contain ALL of these (supports * wildcard)
	// Contains: AND é€»è¾‘ï¼šå¿…é¡»åŒ…å«æ‰€æœ‰è¿™äº›ï¼ˆæ”¯æŒ * é€šé…ç¬¦ï¼‰
	AnyContains []string `yaml:"any_contains"` // OR logic: Must contain AT LEAST ONE of these (supports * wildcard)
	// AnyContains: OR é€»è¾‘ï¼šå¿…é¡»åŒ…å«å…¶ä¸­è‡³å°‘ä¸€ä¸ªï¼ˆæ”¯æŒ * é€šé…ç¬¦ï¼‰
	NotContains []string `yaml:"not_contains"` // NOT logic: Must NOT contain ANY of these (supports * wildcard)
	// NotContains: NOT é€»è¾‘ï¼šä¸èƒ½åŒ…å«å…¶ä¸­ä»»ä½•ä¸€ä¸ªï¼ˆæ”¯æŒ * é€šé…ç¬¦ï¼‰

	// Aliases for better UX (User preference)
	// ä¸ºäº†æ›´å¥½çš„ç”¨æˆ·ä½“éªŒæä¾›çš„åˆ«å
	And []string `yaml:"and"` // Alias for Contains (AND logic)
	// And: Contains çš„åˆ«å (AND é€»è¾‘)
	Is []string `yaml:"is"` // Alias for Contains (AND logic)
	// Is: Contains çš„åˆ«å (AND é€»è¾‘)
	Or []string `yaml:"or"` // Alias for AnyContains (OR logic)
	// Or: AnyContains çš„åˆ«å (OR é€»è¾‘)
	Not []string `yaml:"not"` // Alias for NotContains (NOT logic)
	// Not: NotContains çš„åˆ«å (NOT é€»è¾‘)

	Regex string `yaml:"regex"` // Regular expression to match
	// Regex: æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
	Threshold int `yaml:"threshold"` // Trigger count
	// Threshold: è§¦å‘é˜ˆå€¼
	Interval int `yaml:"interval"` // Time window in seconds (default 60)
	// Interval: æ—¶é—´çª—å£ï¼ˆç§’ï¼Œé»˜è®¤ 60ï¼‰
	TTL string `yaml:"ttl"` // Block duration (e.g., "10m", "1h"). Empty or "0" means permanent/static or LRU auto-evict.
	// TTL: å°ç¦æŒç»­æ—¶é—´ï¼ˆä¾‹å¦‚ "10m", "1h"ï¼‰ã€‚ä¸ºç©ºæˆ– "0" è¡¨ç¤ºæ°¸ä¹…æˆ– LRU è‡ªåŠ¨é©±é€ã€‚
}

// RateLimitConfig defines the configuration for rate limiting.
// RateLimitConfig å®šä¹‰é€Ÿç‡é™åˆ¶é…ç½®ã€‚
type RateLimitConfig struct {
	Enabled         bool   `yaml:"enabled"`
	AutoBlock       bool   `yaml:"auto_block"`
	AutoBlockExpiry string `yaml:"auto_block_expiry"` // e.g., "5m", "1h"
	// AutoBlockExpiry: è‡ªåŠ¨å°ç¦è¿‡æœŸæ—¶é—´ï¼ˆä¾‹å¦‚ "5m", "1h"ï¼‰
	Rules []RateLimitRule `yaml:"rules"`
}

// RateLimitRule defines a rate limit rule for a specific IP/CIDR.
// RateLimitRule å®šä¹‰ç‰¹å®š IP/CIDR çš„é€Ÿç‡é™åˆ¶è§„åˆ™ã€‚
type RateLimitRule struct {
	IP    string `yaml:"ip"`
	Rate  uint64 `yaml:"rate"`
	Burst uint64 `yaml:"burst"`
}

// WebConfig defines the configuration for the web interface.
// WebConfig å®šä¹‰ Web ç•Œé¢é…ç½®ã€‚
type WebConfig struct {
	Enabled bool   `yaml:"enabled"`
	Port    int    `yaml:"port"`
	Token   string `yaml:"token"`
}

// AIConfig defines the configuration for AI features.
// AIConfig å®šä¹‰ AI åŠŸèƒ½é…ç½®ã€‚
type AIConfig struct {
	Enabled bool   `yaml:"enabled"`
	Port    int    `yaml:"port"`
	Model   string `yaml:"model"`
	APIKey  string `yaml:"api_key"`
	BaseURL string `yaml:"base_url"`
}

// MCPConfig defines the configuration for Model Context Protocol.
// MCPConfig å®šä¹‰æ¨¡å‹ä¸Šä¸‹æ–‡åè®® (MCP) é…ç½®ã€‚
type MCPConfig struct {
	Enabled bool   `yaml:"enabled"`
	Port    int    `yaml:"port"`
	Mode    string `yaml:"mode"` // "stdio", "sse"
}

// ClusterConfig defines the configuration for clustering.
// ClusterConfig å®šä¹‰é›†ç¾¤é…ç½®ã€‚
// For standalone mode, only enabled and configpath are used.
// For cluster mode, detailed config is read from the configpath file.
// å•æœºç‰ˆåªä½¿ç”¨ enabled å’Œ configpathï¼Œé›†ç¾¤ç‰ˆä» configpath æ–‡ä»¶è¯»å–è¯¦ç»†é…ç½®ã€‚
type ClusterConfig struct {
	Enabled    bool   `yaml:"enabled"`    // Enable cluster mode / å¯ç”¨é›†ç¾¤æ¨¡å¼
	ConfigPath string `yaml:"configpath"` // Path to cluster config file / é›†ç¾¤é…ç½®æ–‡ä»¶è·¯å¾„
}

// CapacityConfig defines the capacity settings for BPF maps.
// CapacityConfig å®šä¹‰ BPF Map çš„å®¹é‡è®¾ç½®ã€‚
type CapacityConfig struct {
	Conntrack    int `yaml:"-"` // Deprecated: Use Conntrack.MaxEntries / å·²å¼ƒç”¨ï¼šä½¿ç”¨ Conntrack.MaxEntries
	LockList     int `yaml:"lock_list"`
	DynLockList  int `yaml:"dyn_lock_list"`
	Whitelist    int `yaml:"whitelist"`
	IPPortRules  int `yaml:"ip_port_rules"`
	AllowedPorts int `yaml:"allowed_ports"`
	// Stats map capacities (per minute capacity for top IP/port analysis)
	// ç»Ÿè®¡ Map å®¹é‡ï¼ˆæ¯åˆ†é’Ÿå®¹é‡ï¼Œç”¨äº top IP/ç«¯å£åˆ†æï¼‰
	DropReasonStats int `yaml:"drop_reason_stats"` // Drop reason stats map size / ä¸¢å¼ƒåŸå› ç»Ÿè®¡ Map å¤§å°
	PassReasonStats int `yaml:"pass_reason_stats"` // Pass reason stats map size / é€šè¿‡åŸå› ç»Ÿè®¡ Map å¤§å°
}

// BaseConfig defines the base firewall settings.
// BaseConfig å®šä¹‰åŸºç¡€é˜²ç«å¢™è®¾ç½®ã€‚
type BaseConfig struct {
	DefaultDeny        bool `yaml:"default_deny"`
	AllowReturnTraffic bool `yaml:"allow_return_traffic"` // Stateless check (ACK + Port range)
	// AllowReturnTraffic: æ— çŠ¶æ€æ£€æŸ¥ï¼ˆACK + ç«¯å£èŒƒå›´ï¼‰
	AllowICMP      bool     `yaml:"allow_icmp"`
	Interfaces     []string `yaml:"interfaces"`
	EnableAFXDP    bool     `yaml:"enable_af_xdp"`
	StrictProtocol bool     `yaml:"strict_protocol"`
	DropFragments  bool     `yaml:"drop_fragments"`
	StrictTCP      bool     `yaml:"strict_tcp"`
	SYNLimit       bool     `yaml:"syn_limit"`
	BogonFilter    bool     `yaml:"bogon_filter"`
	ICMPRate       uint64   `yaml:"icmp_rate"` // packets per second
	// ICMPRate: æ¯ç§’åŒ…æ•°
	ICMPBurst uint64 `yaml:"icmp_burst"` // max burst
	// ICMPBurst: æœ€å¤§çªå‘é‡
	Whitelist              []string `yaml:"whitelist"`
	LockListFile           string   `yaml:"lock_list_file"`
	LockListBinary         string   `yaml:"lock_list_binary"`
	LockListMergeThreshold int      `yaml:"lock_list_merge_threshold"` // If > 0, merge IPs into /24 (IPv4) or /64 (IPv6) if count >= threshold
	// LockListMergeThreshold: å¦‚æœ > 0ï¼Œå½“æ•°é‡ >= é˜ˆå€¼æ—¶å°† IP åˆå¹¶ä¸ºå­ç½‘
	LockListV4Mask int `yaml:"lock_list_v4_mask"` // Target mask for IPv4 merging (default 24)
	// LockListV4Mask: IPv4 åˆå¹¶çš„ç›®æ ‡æ©ç ï¼ˆé»˜è®¤ 24ï¼‰
	LockListV6Mask int `yaml:"lock_list_v6_mask"` // Target mask for IPv6 merging (default 64)
	// LockListV6Mask: IPv6 åˆå¹¶çš„ç›®æ ‡æ©ç ï¼ˆé»˜è®¤ 64ï¼‰
	BPFPinPath string `yaml:"bpf_pin_path"` // Path to pin BPF maps (override default)
	// BPFPinPath: å›ºå®š BPF Map çš„è·¯å¾„ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰
	EnableExpiry    bool   `yaml:"enable_expiry"`
	CleanupInterval string `yaml:"cleanup_interval"`
	PersistRules    bool   `yaml:"persist_rules"`
	EnablePprof     bool   `yaml:"enable_pprof"`
	PprofPort       int    `yaml:"pprof_port"`
}

// ConntrackConfig defines the configuration for connection tracking.
// ConntrackConfig å®šä¹‰è¿æ¥è·Ÿè¸ªé…ç½®ã€‚
type ConntrackConfig struct {
	Enabled    bool   `yaml:"enabled"`
	MaxEntries int    `yaml:"max_entries"`
	TCPTimeout string `yaml:"tcp_timeout"`
	UDPTimeout string `yaml:"udp_timeout"`
}

// MetricsConfig defines the configuration for metrics collection.
// MetricsConfig å®šä¹‰æŒ‡æ ‡æ”¶é›†é…ç½®ã€‚
type MetricsConfig struct {
	Enabled         bool   `yaml:"enabled"`
	ServerEnabled   bool   `yaml:"server_enabled"`
	Port            int    `yaml:"port"`
	PushEnabled     bool   `yaml:"push_enabled"`
	PushGatewayAddr string `yaml:"push_gateway_addr"`
	PushInterval    string `yaml:"push_interval"`
	TextfileEnabled bool   `yaml:"textfile_enabled"`
	TextfilePath    string `yaml:"textfile_path"`
}

// PortConfig defines the configuration for port filtering.
// PortConfig å®šä¹‰ç«¯å£è¿‡æ»¤é…ç½®ã€‚
type PortConfig struct {
	AllowedPorts []uint16     `yaml:"allowed_ports"`
	IPPortRules  []IPPortRule `yaml:"ip_port_rules"`
}

// IPPortRule defines a filtering rule for a specific IP and port.
// IPPortRule å®šä¹‰ç‰¹å®š IP å’Œç«¯å£çš„è¿‡æ»¤è§„åˆ™ã€‚
type IPPortRule struct {
	IP     string `yaml:"ip"`
	Port   uint16 `yaml:"port"`
	Action uint8  `yaml:"action"` // 1: allow, 2: deny
}

// LoadGlobalConfig loads the configuration from a YAML file.
// LoadGlobalConfig ä» YAML æ–‡ä»¶åŠ è½½é…ç½®ã€‚
func LoadGlobalConfig(path string) (*GlobalConfig, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}

	// Initialize with defaults / ä½¿ç”¨é»˜è®¤å€¼åˆå§‹åŒ–
	cfg := GlobalConfig{
		Cluster: ClusterConfig{
			Enabled:    false,
			ConfigPath: "cluster.yaml",
		},
		Base: BaseConfig{
			DefaultDeny:        true,
			AllowReturnTraffic: false,
			AllowICMP:          true,
			PersistRules:       true,
			CleanupInterval:    "1m",
			ICMPRate:           10,
			ICMPBurst:          50,
			LockListV4Mask:     24,
			LockListV6Mask:     64,
			EnablePprof:        false,
			PprofPort:          6060,
		},
		Conntrack: ConntrackConfig{
			Enabled:    true,
			MaxEntries: 100000,
			TCPTimeout: "1h",
			UDPTimeout: "5m",
		},
		RateLimit: RateLimitConfig{
			Enabled:         true,
			AutoBlock:       true,
			AutoBlockExpiry: "10m",
		},
		LogEngine: LogEngineConfig{
			Enabled: false,
			Workers: 4,
		},
		Capacity: CapacityConfig{
			Conntrack:       100000,
			LockList:        2000000,
			Whitelist:       65536,
			IPPortRules:     65536,
			AllowedPorts:    1024,
			DropReasonStats: 1000000, // 1 million entries per minute / æ¯åˆ†é’Ÿ 100 ä¸‡æ¡ç›®
			PassReasonStats: 1000000, // 1 million entries per minute / æ¯åˆ†é’Ÿ 100 ä¸‡æ¡ç›®
		},
		Logging: LoggingConfig{
			Enabled:    false,
			Path:       "/var/log/netxfw/agent.log",
			MaxSize:    10, // 10MB
			MaxBackups: 3,
			MaxAge:     30, // 30 days
			Compress:   true,
		},

		Web: WebConfig{
			Port: 11811,
		},
		Metrics: MetricsConfig{
			Enabled:       false,
			ServerEnabled: false,
			Port:          11812,
		},
		AI: AIConfig{
			Enabled: false,
			Port:    11813,
		},
		MCP: MCPConfig{
			Enabled: false,
			Port:    11814,
			Mode:    "sse",
		},
	}

	err = yaml.Unmarshal(data, &cfg)
	if err != nil {
		return nil, err
	}

	// Validate configuration / éªŒè¯é…ç½®
	if err := cfg.Validate(); err != nil {
		return nil, fmt.Errorf("configuration validation failed: %w", err)
	}

	// Check for missing keys and update file if needed
	checkForUpdates(path, &cfg, data)

	return &cfg, nil
}

func checkForUpdates(path string, cfg *GlobalConfig, data []byte) {
	// 1. Unmarshal default config (TEMPLATE) to Node (Source of Truth for structure & comments)
	// We use DefaultConfigTemplate instead of marshaling cfg to preserve comments.
	var defaultNode yaml.Node
	if err := yaml.Unmarshal([]byte(DefaultConfigTemplate), &defaultNode); err != nil {
		log.Printf("âš ï¸  Failed to parse default config template: %v", err)
		return
	}

	// 2. Unmarshal existing file to Node (Target to update)
	var fileNode yaml.Node
	if err := yaml.Unmarshal(data, &fileNode); err != nil {
		log.Printf("âš ï¸  Config file seems malformed, skipping auto-update check: %v", err)
		return
	}

	// 3. Merge missing keys from defaultNode into fileNode
	// We want to keep fileNode's values, but add missing keys from defaultNode (with comments).
	// Currently MergeYamlNodes(target, source) updates target with source.
	// If we use MergeYamlNodes(&defaultNode, &fileNode), defaultNode becomes the master.
	// defaultNode has comments. fileNode has user values.
	// Result: defaultNode structure + comments + user values + user extra keys.
	// This effectively "repairs" the config file structure while keeping values.
	MergeYamlNodes(&defaultNode, &fileNode)

	// Check if content changed before writing
	var buf bytes.Buffer
	enc := yaml.NewEncoder(&buf)
	enc.SetIndent(2)
	if err := enc.Encode(&defaultNode); err != nil {
		log.Printf("âŒ Failed to encode updated config: %v", err)
		return
	}

	if bytes.Equal(buf.Bytes(), data) {
		// No changes (including comments), skip write
		return
	}

	log.Println("ğŸ”„ Refreshing configuration file structure and comments...")

	// Backup original
	backupPath := path + ".bak." + time.Now().Format("20060102-150405")
	if err := os.WriteFile(backupPath, data, 0644); err != nil {
		log.Printf("âš ï¸  Failed to backup config file, skipping update: %v", err)
		return
	}

	// Cleanup old backups (Keep latest 3) / æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘ 3 ä¸ªï¼‰
	cleanupBackups(path, 3)

	// Write new config (defaultNode now contains merged state)
	// yaml.v3 Encoder adds a newline
	if err := fileutil.AtomicWriteFile(path, buf.Bytes(), 0644); err != nil {
		log.Printf("âŒ Failed to update config file: %v", err)
	} else {
		log.Println("âœ… Configuration file updated (comments restored/preserved).")
	}
}

// updateYamlNode recursively adds keys from defaultNode to fileNode if they are missing.
// Returns true if any change was made.
// updateYamlNode é€’å½’åœ°å°† defaultNode ä¸­ç¼ºå¤±çš„é”®æ·»åŠ åˆ° fileNodeã€‚
// å¦‚æœè¿›è¡Œäº†ä»»ä½•æ›´æ”¹ï¼Œåˆ™è¿”å› trueã€‚
//
//nolint:unused
func updateYamlNode(fileNode, defaultNode *yaml.Node) bool {
	if fileNode.Kind == yaml.DocumentNode && defaultNode.Kind == yaml.DocumentNode {
		return updateYamlNode(fileNode.Content[0], defaultNode.Content[0])
	}
	if fileNode.Kind != yaml.MappingNode || defaultNode.Kind != yaml.MappingNode {
		return false
	}

	modified := false

	// Iterate over keys in defaultNode (Key, Value pairs)
	for i := 0; i < len(defaultNode.Content); i += 2 {
		keyNode := defaultNode.Content[i]
		valNode := defaultNode.Content[i+1]

		// Check if key exists in fileNode
		var fileValNode *yaml.Node
		for j := 0; j < len(fileNode.Content); j += 2 {
			if fileNode.Content[j].Value == keyNode.Value {
				fileValNode = fileNode.Content[j+1]
				break
			}
		}

		if fileValNode == nil {
			// Key missing, append Key and Value
			// We append the nodes directly.
			fileNode.Content = append(fileNode.Content, keyNode, valNode)
			modified = true
		} else if fileValNode.Kind == yaml.MappingNode && valNode.Kind == yaml.MappingNode {
			// Key exists, recurse if both are mappings
			if updateYamlNode(fileValNode, valNode) {
				modified = true
			}
		}
	}
	return modified
}

// hasMissingKeys checks if file is missing keys from full.
// Deprecated: logic moved to updateYamlNode
// hasMissingKeys æ£€æŸ¥ file æ˜¯å¦ç¼ºå°‘ full ä¸­çš„é”®ã€‚
// å·²å¼ƒç”¨ï¼šé€»è¾‘å·²ç§»è‡³ updateYamlNode
//
//nolint:unused
func hasMissingKeys(full, file map[string]interface{}) bool {
	// Deprecated: logic moved to updateYamlNode
	return false
}

func SaveGlobalConfig(path string, cfg *GlobalConfig) error {
	// 1. Marshal new config to Node
	data, err := yaml.Marshal(cfg)
	if err != nil {
		return err
	}
	var newNode yaml.Node
	if unmarshalErr := yaml.Unmarshal(data, &newNode); unmarshalErr != nil {
		return unmarshalErr
	}

	// 2. Read existing file to Node (if exists)
	fileData, readErr := os.ReadFile(path)
	if readErr == nil {
		var fileNode yaml.Node
		if unmarshalErr := yaml.Unmarshal(fileData, &fileNode); unmarshalErr == nil {
			// 3. Clean deprecated cluster fields BEFORE merge (to remove old fields)
			// åœ¨åˆå¹¶ä¹‹å‰æ¸…ç†å·²å¼ƒç”¨çš„é›†ç¾¤å­—æ®µï¼ˆä»¥ç§»é™¤æ—§å­—æ®µï¼‰
			CleanDeprecatedClusterFields(&fileNode)

			// 4. Merge new config INTO file config (preserving comments)
			MergeYamlNodes(&fileNode, &newNode)

			// Encode back
			var buf bytes.Buffer
			enc := yaml.NewEncoder(&buf)
			enc.SetIndent(2)
			if encodeErr := enc.Encode(&fileNode); encodeErr != nil {
				return encodeErr
			}
			return fileutil.AtomicWriteFile(path, buf.Bytes(), 0644)
		}
	}

	// Fallback if file doesn't exist or is malformed: just write the new config
	return fileutil.AtomicWriteFile(path, data, 0644)
}

// MergeYamlNodes updates target (existing file) with source (new config).
// It preserves comments from target where possible.
// For cluster config, it removes deprecated fields (port, nodes, secret) that are no longer in the struct.
func MergeYamlNodes(target, source *yaml.Node) {
	if target.Kind == yaml.DocumentNode {
		if source.Kind == yaml.DocumentNode {
			MergeYamlNodes(target.Content[0], source.Content[0])
		}
		return
	}

	if target.Kind != yaml.MappingNode || source.Kind != yaml.MappingNode {
		// Replace target with source, but try to keep comments
		// Copy comments from target (old) to source (new)
		if source.HeadComment == "" {
			source.HeadComment = target.HeadComment
		}
		if source.LineComment == "" {
			source.LineComment = target.LineComment
		}
		if source.FootComment == "" {
			source.FootComment = target.FootComment
		}

		*target = *source
		return
	}

	// Both are MappingNodes.
	// We want to preserve Target's structure/comments (Default Config)
	// and update it with Source's values (User Config).
	// We also want to keep any extra keys from Source that are not in Target.

	// 1. Map Source keys for lookup
	sourceMap := make(map[string]int)
	for i := 0; i < len(source.Content); i += 2 {
		sourceMap[source.Content[i].Value] = i
	}

	var newContent []*yaml.Node
	processedSourceKeys := make(map[string]bool)

	// 2. Iterate Target (Default) keys
	for i := 0; i < len(target.Content); i += 2 {
		tKey := target.Content[i]
		tVal := target.Content[i+1]

		if sIdx, ok := sourceMap[tKey.Value]; ok {
			// Key exists in Source: Merge Source value into Target value
			sVal := source.Content[sIdx+1]
			MergeYamlNodes(tVal, sVal)
			processedSourceKeys[tKey.Value] = true
		}
		// Always append Target key/value (to keep comments and order)
		newContent = append(newContent, tKey, tVal)
	}

	// 3. Append keys from Source that were not in Target
	for i := 0; i < len(source.Content); i += 2 {
		sKey := source.Content[i]
		sVal := source.Content[i+1]
		if !processedSourceKeys[sKey.Value] {
			newContent = append(newContent, sKey, sVal)
		}
	}

	target.Content = newContent
}

// CleanDeprecatedClusterFields removes deprecated cluster fields from the config file.
// This is called during config save to clean up old fields that are no longer in the struct.
// CleanDeprecatedClusterFields ä»é…ç½®æ–‡ä»¶ä¸­ç§»é™¤å·²å¼ƒç”¨çš„é›†ç¾¤å­—æ®µã€‚
// è¿™åœ¨é…ç½®ä¿å­˜æœŸé—´è°ƒç”¨ï¼Œç”¨äºæ¸…ç†ç»“æ„ä½“ä¸­ä¸å†å­˜åœ¨çš„æ—§å­—æ®µã€‚
func CleanDeprecatedClusterFields(target *yaml.Node) {
	if target.Kind == yaml.DocumentNode && len(target.Content) > 0 {
		CleanDeprecatedClusterFields(target.Content[0])
		return
	}

	if target.Kind != yaml.MappingNode {
		return
	}

	// Find cluster key in target
	clusterIdx := -1
	for i := 0; i < len(target.Content); i += 2 {
		if target.Content[i].Value == "cluster" {
			clusterIdx = i + 1
			break
		}
	}

	if clusterIdx == -1 {
		return
	}

	clusterNode := target.Content[clusterIdx]
	if clusterNode.Kind != yaml.MappingNode {
		return
	}

	// Deprecated fields to remove / è¦ç§»é™¤çš„å·²å¼ƒç”¨å­—æ®µ
	deprecatedFields := map[string]bool{
		"port":     true,
		"nodes":    true,
		"secret":   true,
		"node_id":  true,
		"election": true,
		"sync":     true,
		"failover": true,
	}

	// Filter out deprecated fields / è¿‡æ»¤æ‰å·²å¼ƒç”¨å­—æ®µ
	var newContent []*yaml.Node
	for i := 0; i < len(clusterNode.Content); i += 2 {
		key := clusterNode.Content[i].Value
		if !deprecatedFields[key] {
			newContent = append(newContent, clusterNode.Content[i], clusterNode.Content[i+1])
		}
	}

	clusterNode.Content = newContent
}

// cleanupBackups keeps only the latest N backup files.
func cleanupBackups(originalPath string, keep int) {
	dir := filepath.Dir(originalPath)
	baseName := filepath.Base(originalPath)
	pattern := baseName + ".bak.*"

	matches, err := filepath.Glob(filepath.Join(dir, pattern))
	if err != nil {
		return
	}

	if len(matches) <= keep {
		return
	}

	// Sort by name (timestamp allows chronological sorting)
	sort.Strings(matches)

	// Remove oldest
	toRemove := matches[:len(matches)-keep]
	for _, f := range toRemove {
		if err := os.Remove(f); err == nil {
			log.Printf("ğŸ—‘ï¸ Removed old backup: %s", f)
		}
	}
}
